{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Classification — Featureless Model (Speed + Turning Angle only)\n",
    "\n",
    "Objectif : prédire si un worm est **drugged** ou **control** à partir de segments\n",
    "de mouvement bruts, en utilisant uniquement **Speed** et **turning_angle**.\n",
    "\n",
    "On enlève volontairement X et Y pour éviter que le modèle exploite la position\n",
    "sur la plaque (les worms drogués étant spatialement groupés).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier  # si pas installé: pip install xgboost\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "\n",
    "# Dossier contenant les segments pré-traités\n",
    "SEGMENTS_DIR = \"preprocessed_data/segments\"\n",
    "\n",
    "# Longueur d'un segment (en frames)\n",
    "SEGMENT_LENGTH = 900\n",
    "\n",
    "# Features utilisées (SANS X, Y)\n",
    "FEATURE_COLS = [\"Speed\", \"turning_angle\"]\n",
    "\n",
    "# Noms de colonnes dans les CSV de segments pré-traités\n",
    "TIME_COL        = \"GlobalFrame\"\n",
    "SOURCE_FILE_COL = \"source_file\"     # identifiant du worm\n",
    "SEGMENT_IDX_COL = \"Segment_index\"\n",
    "CONDITION_COL   = \"condition\"       # contient l'info drug/control\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspection rapide fichier de segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de fichiers de segments trouvés: 8150\n",
      "Exemples:\n",
      " - coordinates_highestspeed_20240827_10_1_with_time_speed-fragment0.0-preprocessed.csv\n",
      " - coordinates_highestspeed_20240827_10_1_with_time_speed-fragment1.0-preprocessed.csv\n",
      " - coordinates_highestspeed_20240827_10_1_with_time_speed-fragment10.0-preprocessed.csv\n",
      " - coordinates_highestspeed_20240827_10_1_with_time_speed-fragment11.0-preprocessed.csv\n",
      " - coordinates_highestspeed_20240827_10_1_with_time_speed-fragment12.0-preprocessed.csv\n",
      "\n",
      "Colonnes d'un segment d'exemple:\n",
      "['GlobalFrame', 'Timestamp', 'Speed', 'X', 'Y', 'condition', 'source_file', 'Segment_index', 'turning_angle', 'worm_id', 'Segment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalFrame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Speed</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>condition</th>\n",
       "      <th>source_file</th>\n",
       "      <th>Segment_index</th>\n",
       "      <th>turning_angle</th>\n",
       "      <th>worm_id</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-08-27T15:43:40.009947</td>\n",
       "      <td>-0.424172</td>\n",
       "      <td>0.415679</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>control</td>\n",
       "      <td>coordinates_highestspeed_20240827_10_1_with_ti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20240827_piworm10_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-08-27T15:43:42.001966</td>\n",
       "      <td>-0.424172</td>\n",
       "      <td>0.416102</td>\n",
       "      <td>0.405726</td>\n",
       "      <td>control</td>\n",
       "      <td>coordinates_highestspeed_20240827_10_1_with_ti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.215921</td>\n",
       "      <td>20240827_piworm10_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2024-08-27T15:43:44.002485</td>\n",
       "      <td>-0.495096</td>\n",
       "      <td>0.416319</td>\n",
       "      <td>0.405562</td>\n",
       "      <td>control</td>\n",
       "      <td>coordinates_highestspeed_20240827_10_1_with_ti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.200451</td>\n",
       "      <td>20240827_piworm10_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-08-27T15:43:46.002854</td>\n",
       "      <td>-0.401777</td>\n",
       "      <td>0.416455</td>\n",
       "      <td>0.405110</td>\n",
       "      <td>control</td>\n",
       "      <td>coordinates_highestspeed_20240827_10_1_with_ti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198548</td>\n",
       "      <td>20240827_piworm10_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2024-08-27T15:43:48.002383</td>\n",
       "      <td>-0.512398</td>\n",
       "      <td>0.416641</td>\n",
       "      <td>0.404967</td>\n",
       "      <td>control</td>\n",
       "      <td>coordinates_highestspeed_20240827_10_1_with_ti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173521</td>\n",
       "      <td>20240827_piworm10_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobalFrame                   Timestamp     Speed         X         Y  \\\n",
       "0          2.0  2024-08-27T15:43:40.009947 -0.424172  0.415679  0.405714   \n",
       "1          3.0  2024-08-27T15:43:42.001966 -0.424172  0.416102  0.405726   \n",
       "2          4.0  2024-08-27T15:43:44.002485 -0.495096  0.416319  0.405562   \n",
       "3          5.0  2024-08-27T15:43:46.002854 -0.401777  0.416455  0.405110   \n",
       "4          6.0  2024-08-27T15:43:48.002383 -0.512398  0.416641  0.404967   \n",
       "\n",
       "  condition                                        source_file  Segment_index  \\\n",
       "0   control  coordinates_highestspeed_20240827_10_1_with_ti...            0.0   \n",
       "1   control  coordinates_highestspeed_20240827_10_1_with_ti...            0.0   \n",
       "2   control  coordinates_highestspeed_20240827_10_1_with_ti...            0.0   \n",
       "3   control  coordinates_highestspeed_20240827_10_1_with_ti...            0.0   \n",
       "4   control  coordinates_highestspeed_20240827_10_1_with_ti...            0.0   \n",
       "\n",
       "   turning_angle              worm_id  Segment  \n",
       "0       0.000000  20240827_piworm10_1      0.0  \n",
       "1      -0.215921  20240827_piworm10_1      0.0  \n",
       "2      -0.200451  20240827_piworm10_1      0.0  \n",
       "3       0.198548  20240827_piworm10_1      0.0  \n",
       "4      -0.173521  20240827_piworm10_1      0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob.glob(os.path.join(SEGMENTS_DIR, \"*.csv\")))\n",
    "print(\"Nb de fichiers de segments trouvés:\", len(files))\n",
    "print(\"Exemples:\")\n",
    "for f in files[:5]:\n",
    "    print(\" -\", os.path.basename(f))\n",
    "\n",
    "# Inspecter un fichier pour vérifier les colonnes\n",
    "df_example = pd.read_csv(files[0])\n",
    "print(\"\\nColonnes d'un segment d'exemple:\")\n",
    "print(df_example.columns.tolist())\n",
    "df_example.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE_COLS = ['Speed', 'turning_angle']\n"
     ]
    }
   ],
   "source": [
    "def load_segment_file(path):\n",
    "    \"\"\"\n",
    "    Charge un fichier de segment pré-traité et renvoie :\n",
    "      - raw : array (T, len(FEATURE_COLS))\n",
    "      - worm_id : identifiant du worm (source_file)\n",
    "      - segment_index : index de segment\n",
    "      - condition : \"control\", \"terb\", etc.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # vérification des colonnes nécessaires\n",
    "    required = [TIME_COL, SOURCE_FILE_COL, SEGMENT_IDX_COL, CONDITION_COL] + FEATURE_COLS\n",
    "    for c in required:\n",
    "        if c not in df.columns:\n",
    "            raise RuntimeError(f\"Column '{c}' missing in {os.path.basename(path)}\")\n",
    "\n",
    "    # tri temporel\n",
    "    df = df.sort_values(TIME_COL)\n",
    "\n",
    "    worm_id = str(df[SOURCE_FILE_COL].iloc[0])\n",
    "    seg_idx = int(df[SEGMENT_IDX_COL].iloc[0])\n",
    "    condition = str(df[CONDITION_COL].iloc[0]).lower()\n",
    "\n",
    "    raw = df[FEATURE_COLS].to_numpy()\n",
    "\n",
    "    # pad / tronque à SEGMENT_LENGTH frames\n",
    "    if raw.shape[0] < SEGMENT_LENGTH:\n",
    "        pad_len = SEGMENT_LENGTH - raw.shape[0]\n",
    "        pad = np.tile(raw[-1:, :], (pad_len, 1))\n",
    "        raw = np.vstack([raw, pad])\n",
    "    elif raw.shape[0] > SEGMENT_LENGTH:\n",
    "        raw = raw[:SEGMENT_LENGTH, :]\n",
    "\n",
    "    return raw, worm_id, seg_idx, condition\n",
    "\n",
    "print(\"FEATURE_COLS =\", FEATURE_COLS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "charger tous segments et metadonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de segments: 8150\n",
      "                                            filename  \\\n",
      "0  coordinates_highestspeed_20240827_10_1_with_ti...   \n",
      "1  coordinates_highestspeed_20240827_10_1_with_ti...   \n",
      "2  coordinates_highestspeed_20240827_10_1_with_ti...   \n",
      "3  coordinates_highestspeed_20240827_10_1_with_ti...   \n",
      "4  coordinates_highestspeed_20240827_10_1_with_ti...   \n",
      "\n",
      "                                             worm_id  segment_index condition  \n",
      "0  coordinates_highestspeed_20240827_10_1_with_ti...              0   control  \n",
      "1  coordinates_highestspeed_20240827_10_1_with_ti...              1   control  \n",
      "2  coordinates_highestspeed_20240827_10_1_with_ti...             10   control  \n",
      "3  coordinates_highestspeed_20240827_10_1_with_ti...             11   control  \n",
      "4  coordinates_highestspeed_20240827_10_1_with_ti...             12   control  \n",
      "Nb de worms différents: 104\n"
     ]
    }
   ],
   "source": [
    "segment_files = sorted(glob.glob(os.path.join(SEGMENTS_DIR, \"*.csv\")))\n",
    "print(\"Nb de segments:\", len(segment_files))\n",
    "\n",
    "all_features = []\n",
    "meta_rows = []\n",
    "\n",
    "for path in segment_files:\n",
    "    feats, worm_id, seg_idx, cond = load_segment_file(path)\n",
    "    all_features.append(feats)\n",
    "    meta_rows.append({\n",
    "        \"filename\": os.path.basename(path),\n",
    "        \"worm_id\": worm_id,\n",
    "        \"segment_index\": seg_idx,\n",
    "        \"condition\": cond,\n",
    "    })\n",
    "\n",
    "meta_df = pd.DataFrame(meta_rows)\n",
    "print(meta_df.head())\n",
    "print(\"Nb de worms différents:\", meta_df[\"worm_id\"].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cinstruction label drugged/control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions disponibles:\n",
      "condition\n",
      "terbinafine    4076\n",
      "control        4074\n",
      "Name: count, dtype: int64\n",
      "Répartition des labels (0=control, 1=drugged): [4074 4076]\n"
     ]
    }
   ],
   "source": [
    "print(\"Conditions disponibles:\")\n",
    "print(meta_df[\"condition\"].value_counts())\n",
    "\n",
    "# Adapter ce mapping si besoin :\n",
    "def condition_to_label(c: str) -> int:\n",
    "    c = c.lower()\n",
    "    # met ici tous les patterns qui veulent dire \"drugged\"\n",
    "    if \"terb\" in c or \"drug\" in c or \"treated\" in c:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  # control\n",
    "\n",
    "meta_df[\"y\"] = meta_df[\"condition\"].apply(condition_to_label)\n",
    "y = meta_df[\"y\"].values\n",
    "groups = meta_df[\"worm_id\"].values\n",
    "\n",
    "print(\"Répartition des labels (0=control, 1=drugged):\", np.bincount(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construction X_raw et X_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw shape: (8150, 900, 2)\n",
      "X_flat shape: (8150, 1800)\n"
     ]
    }
   ],
   "source": [
    "X_raw = np.stack(all_features)   # (N, 900, 2)\n",
    "N, T, F = X_raw.shape\n",
    "print(\"X_raw shape:\", X_raw.shape)\n",
    "\n",
    "X_flat = X_raw.reshape(N, T * F)  # (N, 1800)\n",
    "print(\"X_flat shape:\", X_flat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split train/val/test groupe par worm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Val / Test: 5726 1275 1149\n",
      "Classes train: [3044 2682]\n",
      "Classes val  : [574 701]\n",
      "Classes test : [456 693]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# 70% train, 30% temp\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, temp_idx = next(gss1.split(X_flat, y, groups))\n",
    "\n",
    "# temp -> 15% val, 15% test\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=43)\n",
    "val_idx_temp, test_idx_temp = next(gss2.split(X_flat[temp_idx], y[temp_idx], groups[temp_idx]))\n",
    "\n",
    "val_idx = temp_idx[val_idx_temp]\n",
    "test_idx = temp_idx[test_idx_temp]\n",
    "\n",
    "print(\"Train / Val / Test:\", len(train_idx), len(val_idx), len(test_idx))\n",
    "print(\"Classes train:\", np.bincount(y[train_idx]))\n",
    "print(\"Classes val  :\", np.bincount(y[val_idx]))\n",
    "print(\"Classes test :\", np.bincount(y[test_idx]))\n",
    "\n",
    "X_train, X_val, X_test = X_flat[train_idx], X_flat[val_idx], X_flat[test_idx]\n",
    "y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_val_sc   = scaler.transform(X_val)\n",
    "X_test_sc  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline gradient boosting (long a run= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 38s, sys: 1.11 s, total: 5min 39s\n",
      "Wall time: 5min 40s\n",
      "=== Validation performance (threshold=0.5) ===\n",
      "ACC=0.467 | F1=0.408 | AUC=0.470\n",
      "\n",
      "=== Test performance (threshold=0.5) ===\n",
      "ACC=0.420 | F1=0.439 | AUC=0.409\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.08,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "%time gb.fit(X_train_sc, y_train)\n",
    "\n",
    "# Validation\n",
    "proba_val = gb.predict_proba(X_val_sc)[:, 1]\n",
    "pred_val  = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "acc_val = accuracy_score(y_val, pred_val)\n",
    "f1_val  = f1_score(y_val, pred_val)\n",
    "auc_val = roc_auc_score(y_val, proba_val)\n",
    "\n",
    "print(\"=== Validation performance (threshold=0.5) ===\")\n",
    "print(f\"ACC={acc_val:.3f} | F1={f1_val:.3f} | AUC={auc_val:.3f}\")\n",
    "\n",
    "# Test\n",
    "proba_test = gb.predict_proba(X_test_sc)[:, 1]\n",
    "pred_test  = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "f1_test  = f1_score(y_test, pred_test)\n",
    "auc_test = roc_auc_score(y_test, proba_test)\n",
    "\n",
    "print(\"\\n=== Test performance (threshold=0.5) ===\")\n",
    "print(f\"ACC={acc_test:.3f} | F1={f1_test:.3f} | AUC={auc_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation groupee (5folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "ACC=0.538 | F1=0.539 | AUC=0.556\n",
      "\n",
      "=== Fold 2 ===\n",
      "ACC=0.508 | F1=0.494 | AUC=0.515\n",
      "\n",
      "=== Fold 3 ===\n",
      "ACC=0.479 | F1=0.417 | AUC=0.476\n",
      "\n",
      "=== Fold 4 ===\n",
      "ACC=0.506 | F1=0.497 | AUC=0.548\n",
      "\n",
      "=== Fold 5 ===\n",
      "ACC=0.402 | F1=0.420 | AUC=0.509\n",
      "\n",
      "=== CV summary (featureless drug classifier) ===\n",
      "ACC  : 0.487 ± 0.046\n",
      "F1   : 0.473 ± 0.048\n",
      "AUC  : 0.521 ± 0.029\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"gb\", GradientBoostingClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.08,\n",
    "        max_depth=3,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "accs, f1s, aucs = [], [], []\n",
    "\n",
    "for fold, (tr, te) in enumerate(cv.split(X_flat, y, groups)):\n",
    "    print(f\"\\n=== Fold {fold+1} ===\")\n",
    "    clf.fit(X_flat[tr], y[tr])\n",
    "    proba = clf.predict_proba(X_flat[te])[:, 1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "    accs.append(accuracy_score(y[te], preds))\n",
    "    f1s.append(f1_score(y[te], preds))\n",
    "    aucs.append(roc_auc_score(y[te], proba))\n",
    "\n",
    "    print(f\"ACC={accs[-1]:.3f} | F1={f1s[-1]:.3f} | AUC={aucs[-1]:.3f}\")\n",
    "\n",
    "print(\"\\n=== CV summary (featureless drug classifier) ===\")\n",
    "print(f\"ACC  : {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n",
    "print(f\"F1   : {np.mean(f1s):.3f} ± {np.std(f1s):.3f}\")\n",
    "print(f\"AUC  : {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model comparison (GB/LogREG/LinearSVM/XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Model comparison (featureless, Speed + turning_angle) ===\")\n",
    "\n",
    "# Nouveau split pour comparaison modèles\n",
    "gss_mc = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "train_idx_mc, test_idx_mc = next(gss_mc.split(X_flat, y, groups))\n",
    "\n",
    "X_train_mc, X_test_mc = X_flat[train_idx_mc], X_flat[test_idx_mc]\n",
    "y_train_mc, y_test_mc = y[train_idx_mc], y[test_idx_mc]\n",
    "\n",
    "scaler_mc = StandardScaler()\n",
    "X_train_mc_sc = scaler_mc.fit_transform(X_train_mc)\n",
    "X_test_mc_sc  = scaler_mc.transform(X_test_mc)\n",
    "\n",
    "models = {\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.08,\n",
    "        max_depth=3,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=500,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LinearSVM\": CalibratedClassifierCV(\n",
    "        LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42),\n",
    "        method=\"sigmoid\",\n",
    "        cv=3\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "results_models = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    model.fit(X_train_mc_sc, y_train_mc)\n",
    "    proba = model.predict_proba(X_test_mc_sc)[:, 1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test_mc, preds)\n",
    "    f1  = f1_score(y_test_mc, preds)\n",
    "    auc = roc_auc_score(y_test_mc, proba)\n",
    "\n",
    "    print(f\"ACC={acc:.3f} | F1={f1:.3f} | AUC={auc:.3f}\")\n",
    "\n",
    "    results_models.append({\"model\": name, \"ACC\": acc, \"F1\": f1, \"AUC\": auc})\n",
    "\n",
    "results_models_df = pd.DataFrame(results_models)\n",
    "results_models_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celegans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
