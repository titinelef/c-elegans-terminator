{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "from preproc_helpers import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (try changing to find best ones)\n",
    "SEGMENT_LENGTH = 900\n",
    "GAP_INTERPOLATION_LIMIT = 6\n",
    "LONG_GAP_THRESHOLD = 7\n",
    "MAX_SPEED_THRESHOLD = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalFrame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fragment</th>\n",
       "      <th>LocalFrame</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>condition</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fragment_0</td>\n",
       "      <td>0</td>\n",
       "      <td>437.288703</td>\n",
       "      <td>379.317992</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-18T14:41:54.008410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fragment_0</td>\n",
       "      <td>1</td>\n",
       "      <td>437.791111</td>\n",
       "      <td>379.808889</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-18T14:41:56.000871</td>\n",
       "      <td>0.333696</td>\n",
       "      <td>fragment_0</td>\n",
       "      <td>2</td>\n",
       "      <td>437.957547</td>\n",
       "      <td>379.797170</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-03-18T14:41:58.001852</td>\n",
       "      <td>0.337566</td>\n",
       "      <td>fragment_0</td>\n",
       "      <td>3</td>\n",
       "      <td>438.087379</td>\n",
       "      <td>379.689320</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-03-18T14:42:00.001812</td>\n",
       "      <td>0.454892</td>\n",
       "      <td>fragment_0</td>\n",
       "      <td>4</td>\n",
       "      <td>438.313131</td>\n",
       "      <td>379.661616</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobalFrame                   Timestamp     Speed    Fragment  LocalFrame  \\\n",
       "0            1                         NaN       NaN  fragment_0           0   \n",
       "1            2  2025-03-18T14:41:54.008410       NaN  fragment_0           1   \n",
       "2            3  2025-03-18T14:41:56.000871  0.333696  fragment_0           2   \n",
       "3            4  2025-03-18T14:41:58.001852  0.337566  fragment_0           3   \n",
       "4            5  2025-03-18T14:42:00.001812  0.454892  fragment_0           4   \n",
       "\n",
       "            X           Y    condition  \\\n",
       "0  437.288703  379.317992  terbinafine   \n",
       "1  437.791111  379.808889  terbinafine   \n",
       "2  437.957547  379.797170  terbinafine   \n",
       "3  438.087379  379.689320  terbinafine   \n",
       "4  438.313131  379.661616  terbinafine   \n",
       "\n",
       "                                         source_file  \n",
       "0  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "1  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "2  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "3  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "4  coordinates_highestspeed_20250318_9_3_with_tim...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading RAW data\n",
    "ROOT = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT, \"TERBINAFINE\")\n",
    "control_dir = os.path.join(DATA_DIR, \"TERBINAFINE- (control)\")\n",
    "treated_dir = os.path.join(DATA_DIR, \"TERBINAFINE+\")\n",
    "\n",
    "# summary file\n",
    "lifespan_df = pd.read_csv(os.path.join(DATA_DIR, \"lifespan_summary.csv\"))\n",
    "#get list of all individual files (take all CSVs)\n",
    "control_files = glob.glob(os.path.join(control_dir, \"*.csv\"))\n",
    "treated_files = glob.glob(os.path.join(treated_dir, \"*.csv\"))\n",
    "\n",
    "#get files, adding a condition column and a column with the file name (to group later?)\n",
    "control_dfs = []\n",
    "for file in control_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"condition\"] = \"control\"\n",
    "    df[\"source_file\"] = os.path.basename(file)\n",
    "    control_dfs.append(df)\n",
    "\n",
    "treated_dfs = []\n",
    "for file in treated_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"condition\"] = \"terbinafine\"\n",
    "    df[\"source_file\"] = os.path.basename(file)\n",
    "    treated_dfs.append(df)\n",
    "\n",
    "\n",
    "lifespan_df.head()\n",
    "treated_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75600, 9)\n",
      "(75301, 9)\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "\n",
    "test_df = trim_after_death(treated_dfs[0], lifespan_df)\n",
    "print(treated_dfs[0].shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75600, 9)\n",
      "(75599, 7)\n",
      "(75300, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalFrame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Speed</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>condition</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-18T14:41:54.008410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.791111</td>\n",
       "      <td>379.808889</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-18T14:41:56.000871</td>\n",
       "      <td>0.333696</td>\n",
       "      <td>437.957547</td>\n",
       "      <td>379.797170</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-03-18T14:41:58.001852</td>\n",
       "      <td>0.337566</td>\n",
       "      <td>438.087379</td>\n",
       "      <td>379.689320</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-03-18T14:42:00.001812</td>\n",
       "      <td>0.454892</td>\n",
       "      <td>438.313131</td>\n",
       "      <td>379.661616</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2025-03-18T14:42:02.001772</td>\n",
       "      <td>0.335773</td>\n",
       "      <td>438.196970</td>\n",
       "      <td>379.782828</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobalFrame                   Timestamp     Speed           X           Y  \\\n",
       "0            2  2025-03-18T14:41:54.008410       NaN  437.791111  379.808889   \n",
       "1            3  2025-03-18T14:41:56.000871  0.333696  437.957547  379.797170   \n",
       "2            4  2025-03-18T14:41:58.001852  0.337566  438.087379  379.689320   \n",
       "3            5  2025-03-18T14:42:00.001812  0.454892  438.313131  379.661616   \n",
       "4            6  2025-03-18T14:42:02.001772  0.335773  438.196970  379.782828   \n",
       "\n",
       "     condition                                        source_file  \n",
       "0  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "1  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "2  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "3  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...  \n",
       "4  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Local Frame and fragment can be ignored (from Alices_explanation)\n",
    "control_dfs_ = [df.drop(columns=[\"Fragment\", \"LocalFrame\"]) for df in control_dfs]\n",
    "treated_dfs_ = [df.drop(columns=[\"Fragment\", \"LocalFrame\"]) for df in treated_dfs]\n",
    "# remove very first row (useless and aligns for segments)\n",
    "control_dfs_1 = [df.iloc[1:].reset_index(drop=True) for df in control_dfs_]\n",
    "treated_dfs_1 = [df.iloc[1:].reset_index(drop=True) for df in treated_dfs_]\n",
    "#cap extreme speeds\n",
    "control_dfs_cap = [cap_extreme_speeds(df) for df in control_dfs_1]\n",
    "treated_dfs_cap = [cap_extreme_speeds(df) for df in treated_dfs_1]\n",
    "# remove all data after death\n",
    "control_dfs_death = [trim_after_death(df, lifespan_df) for df in control_dfs_cap]\n",
    "treated_dfs_death = [trim_after_death(df, lifespan_df) for df in treated_dfs_cap]\n",
    "\n",
    "print(treated_dfs[0].shape)\n",
    "print(treated_dfs_1[0].shape)\n",
    "print(treated_dfs_death[0].shape)\n",
    "treated_dfs_death[0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalFrame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Speed</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>condition</th>\n",
       "      <th>source_file</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Segment_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>897</td>\n",
       "      <td>2025-03-18T15:11:44.001859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.549669</td>\n",
       "      <td>380.635762</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>898</td>\n",
       "      <td>2025-03-18T15:11:46.001905</td>\n",
       "      <td>0.413905</td>\n",
       "      <td>422.756579</td>\n",
       "      <td>380.631579</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>899</td>\n",
       "      <td>2025-03-18T15:11:48.001797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.756579</td>\n",
       "      <td>380.631579</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>900</td>\n",
       "      <td>2025-03-18T15:11:50.001756</td>\n",
       "      <td>0.250432</td>\n",
       "      <td>422.870968</td>\n",
       "      <td>380.580645</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>901</td>\n",
       "      <td>2025-03-18T15:11:52.001948</td>\n",
       "      <td>0.411985</td>\n",
       "      <td>422.687075</td>\n",
       "      <td>380.673469</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GlobalFrame                   Timestamp     Speed           X  \\\n",
       "895          897  2025-03-18T15:11:44.001859  0.000000  422.549669   \n",
       "896          898  2025-03-18T15:11:46.001905  0.413905  422.756579   \n",
       "897          899  2025-03-18T15:11:48.001797  0.000000  422.756579   \n",
       "898          900  2025-03-18T15:11:50.001756  0.250432  422.870968   \n",
       "899          901  2025-03-18T15:11:52.001948  0.411985  422.687075   \n",
       "\n",
       "              Y    condition  \\\n",
       "895  380.635762  terbinafine   \n",
       "896  380.631579  terbinafine   \n",
       "897  380.631579  terbinafine   \n",
       "898  380.580645  terbinafine   \n",
       "899  380.673469  terbinafine   \n",
       "\n",
       "                                           source_file  Segment  Segment_index  \n",
       "895  coordinates_highestspeed_20250318_9_3_with_tim...        0              0  \n",
       "896  coordinates_highestspeed_20250318_9_3_with_tim...        0              0  \n",
       "897  coordinates_highestspeed_20250318_9_3_with_tim...        0              0  \n",
       "898  coordinates_highestspeed_20250318_9_3_with_tim...        0              0  \n",
       "899  coordinates_highestspeed_20250318_9_3_with_tim...        0              0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create segments test\n",
    "\n",
    "test_segs = split_into_segments(treated_dfs_death[0]) #\n",
    "test_segs[0].tail()\n",
    "\n",
    "# à checker que les segments sont bien faits !!!!!!!!\n",
    "# j'ai checké à l'oeil pour ce segment et ça match le CSV je me dis que c'est bon mais pt être trouver un meilleur moyen de check\n",
    "# j'ai joué avec le -2 dans split_into_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create segments\n",
    "segments_ctrl = [split_into_segments(df) for df in control_dfs_death]\n",
    "segments_treat = [split_into_segments(df) for df in treated_dfs_death]\n",
    "# en théorie c'est des list pour la condition, dedans liste par worm qui contient un df pour chaque segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean segments \n",
    "cleaned_segments_ctrl = []\n",
    "for worm_ctrl in segments_ctrl:\n",
    "    cleaned_segs_ctrl = []\n",
    "    for seg_ctrl in worm_ctrl :\n",
    "        seg_ctrl_cleaned = clean_segment_gaps(seg_ctrl)\n",
    "        seg_ctrl_cleaned = calculate_turning_angle(seg_ctrl_cleaned)\n",
    "        cleaned_segs_ctrl.append(seg_ctrl_cleaned)\n",
    "    cleaned_segments_ctrl.append(cleaned_segs_ctrl)\n",
    "\n",
    "\n",
    "cleaned_segments_treat = []\n",
    "for worm_treat in segments_treat:\n",
    "    cleaned_segs_treat = []\n",
    "    for seg_treat in worm_treat :\n",
    "        seg_treat_cleaned = clean_segment_gaps(seg_treat)\n",
    "        seg_treat_cleaned = calculate_turning_angle(seg_treat_cleaned)\n",
    "        cleaned_segs_treat.append(seg_treat_cleaned)\n",
    "    cleaned_segments_treat.append(cleaned_segs_treat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalFrame</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Speed</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>condition</th>\n",
       "      <th>source_file</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Segment_index</th>\n",
       "      <th>turning_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-18T14:41:54.008410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.791111</td>\n",
       "      <td>379.808889</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-18T14:41:56.000871</td>\n",
       "      <td>0.333696</td>\n",
       "      <td>437.957547</td>\n",
       "      <td>379.797170</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-35.688343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-03-18T14:41:58.001852</td>\n",
       "      <td>0.337566</td>\n",
       "      <td>438.087379</td>\n",
       "      <td>379.689320</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.719679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-03-18T14:42:00.001812</td>\n",
       "      <td>0.454892</td>\n",
       "      <td>438.313131</td>\n",
       "      <td>379.661616</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140.777445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2025-03-18T14:42:02.001772</td>\n",
       "      <td>0.335773</td>\n",
       "      <td>438.196970</td>\n",
       "      <td>379.782828</td>\n",
       "      <td>terbinafine</td>\n",
       "      <td>coordinates_highestspeed_20250318_9_3_with_tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-107.817140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobalFrame                   Timestamp     Speed           X           Y  \\\n",
       "0            2  2025-03-18T14:41:54.008410       NaN  437.791111  379.808889   \n",
       "1            3  2025-03-18T14:41:56.000871  0.333696  437.957547  379.797170   \n",
       "2            4  2025-03-18T14:41:58.001852  0.337566  438.087379  379.689320   \n",
       "3            5  2025-03-18T14:42:00.001812  0.454892  438.313131  379.661616   \n",
       "4            6  2025-03-18T14:42:02.001772  0.335773  438.196970  379.782828   \n",
       "\n",
       "     condition                                        source_file  Segment  \\\n",
       "0  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...        0   \n",
       "1  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...        0   \n",
       "2  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...        0   \n",
       "3  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...        0   \n",
       "4  terbinafine  coordinates_highestspeed_20250318_9_3_with_tim...        0   \n",
       "\n",
       "   Segment_index  turning_angle  \n",
       "0              0       0.000000  \n",
       "1              0     -35.688343  \n",
       "2              0      32.719679  \n",
       "3              0     140.777445  \n",
       "4              0    -107.817140  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verification\n",
    "cleaned_segments_treat[0][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant (en théorie) les segments sont clean, il faut tout reconcat pour chaque worm et normaliser par rapport à la trajectoire entière du worm. Les trajectoires full peuvent être enregistrées, on resepare en segments et on enregistre les segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the segments for each worm and normalize\n",
    "control_dfs_final = []\n",
    "for worm in cleaned_segments_ctrl :\n",
    "    worm_norm = normalize_trajectory_data(pd.concat(worm, ignore_index=True))\n",
    "    control_dfs_final.append(worm_norm)\n",
    "\n",
    "treat_dfs_final = []\n",
    "for worm in cleaned_segments_treat :\n",
    "    worm_norm = normalize_trajectory_data(pd.concat(worm, ignore_index=True))\n",
    "    treat_dfs_final.append(worm_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "#verification, peut être implémenter qqch pour enlever les nans ???\n",
    "i = 0\n",
    "for df in treat_dfs_final: i+=1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO : enregistrer dans un nouveau dossier 'data' dans un dossier 'full'\n",
    "# reséparer fragments, et enregistrer dans autre dossier 'segment' , utiliser l'index \n",
    "# pt être reséparer par condition ? faudra faire gaffe au leakage\n",
    "# comme ça on pourra directement load la data preprocessed pour le reste du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_worm_csv(df, filename, output_dir):\n",
    "    \"\"\"Save a worm dataframe into the output folder\"\"\"\n",
    "    \n",
    "    \n",
    "    # Build full path\n",
    "    out_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full trajectories\n",
    "\n",
    "output_dir = \"preprocessed_data/full\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for df in control_dfs_final:\n",
    "    original = df[\"source_file\"].iloc[0]\n",
    "    base = os.path.splitext(original)[0]    \n",
    "    new_name = f\"{base}-preprocessed.csv\"\n",
    "    save_worm_csv(df, new_name, output_dir)\n",
    "\n",
    "for df in treat_dfs_final:\n",
    "    original = df[\"source_file\"].iloc[0]\n",
    "    base = os.path.splitext(original)[0]    \n",
    "    new_name = f\"{base}-preprocessed.csv\"\n",
    "    save_worm_csv(df, new_name, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all segments (need to reseparate them)\n",
    "\n",
    "segments_dir = \"preprocessed_data/segments\"\n",
    "os.makedirs(segments_dir, exist_ok=True)\n",
    "\n",
    "segments_ctrl_final = [split_into_segments(df) for df in control_dfs_final]\n",
    "segments_treat_final = [split_into_segments(df) for df in treat_dfs_final]\n",
    "\n",
    "for worm in segments_ctrl_final:\n",
    "    for df in worm:\n",
    "        # Skip empty segment\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        original = df[\"source_file\"].iloc[0]\n",
    "        base = os.path.splitext(original)[0] \n",
    "        index = df['Segment_index'].iloc[0]\n",
    "        new_name = f\"{base}-fragment{index}-preprocessed.csv\"\n",
    "        save_worm_csv(df, new_name, segments_dir)\n",
    "\n",
    "for worm in segments_treat_final:\n",
    "    for df in worm:\n",
    "        # Skip empty segment\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        original = df[\"source_file\"].iloc[0]\n",
    "        base = os.path.splitext(original)[0] \n",
    "        index = df['Segment_index'].iloc[0]\n",
    "        new_name = f\"{base}-fragment{index}-preprocessed.csv\"\n",
    "        save_worm_csv(df, new_name, segments_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il y a toujours le file_name dans la data pour pouvoir matcher les segments\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
