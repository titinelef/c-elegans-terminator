{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Death Proximity Classification — Minimal Feature Model\n",
    "\n",
    "In this notebook, we predict whether a behavioral segment is **close to death**\n",
    "using a **small number of hand-crafted “aging” features**.\n",
    "\n",
    "We compare performance (F1, AUC, Accuracy) for:\n",
    "- 1 feature\n",
    "- 2 features\n",
    "- 3 features\n",
    "- 4 features\n",
    "- 6 features\n",
    "- the full set of aging-related features\n",
    "\n",
    "Cross-validation is stratified **by worm**, avoiding any leakage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✓ Imports loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le dataset de features:\n",
    "- Charge le CSV contenant les features par segment (généré par l’assistant du prof).\n",
    "- Affiche le nombre de lignes (= nombre de segments).\n",
    "- Montre les premières lignes pour vérifier les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded segments: 8197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_speed</th>\n",
       "      <th>std_speed</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>min_speed</th>\n",
       "      <th>total_distance</th>\n",
       "      <th>time_paused</th>\n",
       "      <th>fraction_paused</th>\n",
       "      <th>mean_turning_angle</th>\n",
       "      <th>std_turning_angle</th>\n",
       "      <th>max_turning_angle</th>\n",
       "      <th>...</th>\n",
       "      <th>turning_dominant_freq</th>\n",
       "      <th>turning_spectral_centroid</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>high_activity_fraction</th>\n",
       "      <th>low_activity_fraction</th>\n",
       "      <th>mixed_activity_fraction</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>original_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.515196</td>\n",
       "      <td>0.822250</td>\n",
       "      <td>8.953392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309186</td>\n",
       "      <td>85</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.591906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>222.292989</td>\n",
       "      <td>0.187359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.358384</td>\n",
       "      <td>0.386695</td>\n",
       "      <td>3.983101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215078</td>\n",
       "      <td>89</td>\n",
       "      <td>0.098999</td>\n",
       "      <td>-0.039617</td>\n",
       "      <td>0.549625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>217.160606</td>\n",
       "      <td>0.196802</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.498886</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450613</td>\n",
       "      <td>0.681019</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375546</td>\n",
       "      <td>54</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>0.519526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>227</td>\n",
       "      <td>223.010712</td>\n",
       "      <td>0.154898</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.498886</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.142944</td>\n",
       "      <td>1.318301</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.735031</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.552685</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>...</td>\n",
       "      <td>352</td>\n",
       "      <td>229.228829</td>\n",
       "      <td>0.210105</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.498886</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.279008</td>\n",
       "      <td>2.123586</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.029532</td>\n",
       "      <td>1.563521</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.478620</td>\n",
       "      <td>0.997902</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>227.525328</td>\n",
       "      <td>0.256524</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>0.498886</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coordinates_highestspeed_20250311_19_2_with_ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_speed  std_speed  max_speed  min_speed  total_distance  time_paused  \\\n",
       "0    0.515196   0.822250   8.953392   0.000000        0.309186           85   \n",
       "1    0.358384   0.386695   3.983101   0.000000        0.215078           89   \n",
       "2    0.450613   0.681019  10.000000   0.000000        0.375546           54   \n",
       "3    1.142944   1.318301  10.000000   0.000000        1.735031            9   \n",
       "4    2.279008   2.123586  10.000000   0.029532        1.563521            4   \n",
       "\n",
       "   fraction_paused  mean_turning_angle  std_turning_angle  max_turning_angle  \\\n",
       "0         0.094549            0.010376           0.591906           1.000000   \n",
       "1         0.098999           -0.039617           0.549625           1.000000   \n",
       "2         0.060067            0.029493           0.519526           1.000000   \n",
       "3         0.010011            0.003154           0.552685           0.999678   \n",
       "4         0.004449            0.006558           0.478620           0.997902   \n",
       "\n",
       "   ...  turning_dominant_freq  turning_spectral_centroid  activity_level  \\\n",
       "0  ...                     79                 222.292989        0.187359   \n",
       "1  ...                    272                 217.160606        0.196802   \n",
       "2  ...                    227                 223.010712        0.154898   \n",
       "3  ...                    352                 229.228829        0.210105   \n",
       "4  ...                    338                 227.525328        0.256524   \n",
       "\n",
       "   high_activity_fraction  low_activity_fraction  mixed_activity_fraction  \\\n",
       "0                0.000000               0.000000                 0.000000   \n",
       "1                0.250557               0.250557                 0.498886   \n",
       "2                0.250557               0.250557                 0.498886   \n",
       "3                0.250557               0.250557                 0.498886   \n",
       "4                0.250557               0.250557                 0.498886   \n",
       "\n",
       "                                            filename  label  segment_index  \\\n",
       "0  coordinates_highestspeed_20250311_19_2_with_ti...      0            NaN   \n",
       "1  coordinates_highestspeed_20250311_19_2_with_ti...      0            NaN   \n",
       "2  coordinates_highestspeed_20250311_19_2_with_ti...      0            NaN   \n",
       "3  coordinates_highestspeed_20250311_19_2_with_ti...      0            NaN   \n",
       "4  coordinates_highestspeed_20250311_19_2_with_ti...      0            NaN   \n",
       "\n",
       "                                       original_file  \n",
       "0  coordinates_highestspeed_20250311_19_2_with_ti...  \n",
       "1  coordinates_highestspeed_20250311_19_2_with_ti...  \n",
       "2  coordinates_highestspeed_20250311_19_2_with_ti...  \n",
       "3  coordinates_highestspeed_20250311_19_2_with_ti...  \n",
       "4  coordinates_highestspeed_20250311_19_2_with_ti...  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_FILE = \"feature_data/segments_features.csv\"\n",
    "\n",
    "df = pd.read_csv(FEATURE_FILE)\n",
    "print(f\"Loaded segments: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruire segment_index et segments_from_end + label \n",
    "- Reconstruit segment_index à partir du nom du fichier si la colonne est absente.\n",
    "- Pour chaque ver (original_file), récupère l’index du dernier segment. \n",
    "- Calcule segments_from_end = combien de segments il reste avant la mort pour chaque segment.\n",
    "- Crée le label binaire :\n",
    "    - 1 si le segment est dans les 20 derniers segments,\n",
    "    - 0 sinon.\n",
    "\n",
    "- Stocke :\n",
    "    - y = labels,\n",
    "    - groups = id du ver (pour split sans fuite).\n",
    "\n",
    "Affiche la distribution des labels (important pour voir le déséquilibre de classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution (0=not near-death, 1=near-death): [6061 2136]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segments_from_end</th>\n",
       "      <th>close_to_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   segment_index  segments_from_end  close_to_death\n",
       "0            0.0              108.0               0\n",
       "1            1.0              107.0               0\n",
       "2            2.0              106.0               0\n",
       "3            3.0              105.0               0\n",
       "4            4.0              104.0               0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segment_index à partir du nom de fichier si besoin\n",
    "if \"segment_index\" not in df.columns or df[\"segment_index\"].isna().all():\n",
    "    df[\"segment_index\"] = df[\"filename\"].str.extract(\n",
    "        r\"segment(\\d+(?:\\.\\d+)?)\", expand=False\n",
    "    ).astype(float)\n",
    "\n",
    "df[\"original_file\"] = df[\"original_file\"].astype(str)\n",
    "\n",
    "# distance à la mort en nombre de segments\n",
    "max_seg = df.groupby(\"original_file\")[\"segment_index\"].max()\n",
    "\n",
    "df[\"segments_from_end\"] = df.apply(\n",
    "    lambda row: max_seg[row[\"original_file\"]] - row[\"segment_index\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# label binaire : proche de la mort ou pas\n",
    "PROXIMITY_THRESHOLD = 20  # segments\n",
    "df[\"close_to_death\"] = (df[\"segments_from_end\"] <= PROXIMITY_THRESHOLD).astype(int)\n",
    "\n",
    "y = df[\"close_to_death\"].values\n",
    "groups = df[\"original_file\"].values\n",
    "\n",
    "print(\"Label distribution (0=not near-death, 1=near-death):\", np.bincount(y))\n",
    "df[[\"segment_index\", \"segments_from_end\", \"close_to_death\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir les subsets de features:\n",
    "- Liste toutes les features d’aging calculées par l’assistant.\n",
    "- Restreint à celles qui existent effectivement dans le CSV (available_features).\n",
    "- Définit un petit set ordonné de features “noyau” (ranked_core) :\n",
    "    - vitesse moyenne,\n",
    "    - entropie de vitesse,\n",
    "    - score de roaming,\n",
    "    - fraction de temps en pause,\n",
    "    - efficacité de mouvement,\n",
    "    - fraction de haute activité.\n",
    "\n",
    "Crée plusieurs subsets :\n",
    "- 1 feature, 2, 3, 4, 6, toutes.\n",
    "\n",
    "Affiche clairement quelles features sont utilisées dans chaque subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE SUBSETS USED ===\n",
      "\n",
      "1_feature       (1 features):\n",
      "   - mean_speed\n",
      "\n",
      "2_features      (2 features):\n",
      "   - mean_speed\n",
      "   - speed_entropy\n",
      "\n",
      "3_features      (3 features):\n",
      "   - mean_speed\n",
      "   - speed_entropy\n",
      "   - mean_roaming_score\n",
      "\n",
      "4_features      (4 features):\n",
      "   - mean_speed\n",
      "   - speed_entropy\n",
      "   - mean_roaming_score\n",
      "   - fraction_paused\n",
      "\n",
      "6_features      (6 features):\n",
      "   - mean_speed\n",
      "   - speed_entropy\n",
      "   - mean_roaming_score\n",
      "   - fraction_paused\n",
      "   - movement_efficiency\n",
      "   - high_activity_fraction\n",
      "\n",
      "all_top_aging   (29 features):\n",
      "   - high_activity_fraction\n",
      "   - mixed_activity_fraction\n",
      "   - low_activity_fraction\n",
      "   - mean_speed\n",
      "   - std_speed\n",
      "   - max_speed\n",
      "   - speed_entropy\n",
      "   - mean_roaming_score\n",
      "   - std_roaming_score\n",
      "   - fraction_roaming\n",
      "   - movement_efficiency\n",
      "   - fraction_efficient_movement\n",
      "   - time_paused\n",
      "   - fraction_paused\n",
      "   - mean_jerk\n",
      "   - max_jerk\n",
      "   - kinetic_energy_proxy\n",
      "   - mean_meandering_ratio\n",
      "   - std_meandering_ratio\n",
      "   - wavelet_speed_level0\n",
      "   - wavelet_speed_level1\n",
      "   - wavelet_speed_level2\n",
      "   - wavelet_speed_level3\n",
      "   - mean_frenetic_score\n",
      "   - std_frenetic_score\n",
      "   - speed_persistence\n",
      "   - activity_level\n",
      "   - speed_skewness\n",
      "   - speed_kurtosis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensemble complet de features \"aging\" fournies par l'assistant\n",
    "top_aging_features = [\n",
    "    \"high_activity_fraction\", \"mixed_activity_fraction\", \"low_activity_fraction\",\n",
    "    \"mean_speed\", \"std_speed\", \"max_speed\", \"speed_entropy\",\n",
    "    \"mean_roaming_score\", \"std_roaming_score\", \"fraction_roaming\",\n",
    "    \"movement_efficiency\", \"fraction_efficient_movement\",\n",
    "    \"time_paused\", \"fraction_paused\",\n",
    "    \"mean_jerk\", \"max_jerk\", \"kinetic_energy_proxy\",\n",
    "    \"mean_meandering_ratio\", \"std_meandering_ratio\",\n",
    "    \"wavelet_speed_level0\", \"wavelet_speed_level1\", \"wavelet_speed_level2\", \"wavelet_speed_level3\",\n",
    "    \"mean_frenetic_score\", \"std_frenetic_score\",\n",
    "    \"speed_persistence\", \"activity_level\", \"speed_skewness\", \"speed_kurtosis\"\n",
    "]\n",
    "\n",
    "available_features = [f for f in top_aging_features if f in df.columns]\n",
    "\n",
    "# Features les plus \"centrales\" pour l'aging / near-death\n",
    "ranked_core = [\n",
    "    \"mean_speed\",\n",
    "    \"speed_entropy\",\n",
    "    \"mean_roaming_score\",\n",
    "    \"fraction_paused\",\n",
    "    \"movement_efficiency\",\n",
    "    \"high_activity_fraction\"\n",
    "]\n",
    "\n",
    "feature_subsets = {\n",
    "    \"1_feature\": ranked_core[:1],\n",
    "    \"2_features\": ranked_core[:2],\n",
    "    \"3_features\": ranked_core[:3],\n",
    "    \"4_features\": ranked_core[:4],\n",
    "    \"6_features\": ranked_core[:6],\n",
    "    \"all_top_aging\": available_features,\n",
    "}\n",
    "\n",
    "print(\"=== FEATURE SUBSETS USED ===\\n\")\n",
    "for name, feats in feature_subsets.items():\n",
    "    print(f\"{name:15s} ({len(feats)} features):\")\n",
    "    for f in feats:\n",
    "        print(f\"   - {f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: Cross Val par worm \n",
    "- Définit une fonction utilitaire evaluate_feature_subsets qui :\n",
    "    - prend le DataFrame, les labels, les groupes, et le dict de subsets,\n",
    "    - pour chaque subset :\n",
    "        - récupère les colonnes correspondantes,\n",
    "        - remplace les NaNs par la médiane (par feature),\n",
    "        - construit un Pipeline :\n",
    "            - StandardScaler → normalisation,\n",
    "            - GradientBoostingClassifier → modèle non linéaire robuste,\n",
    "        - fait une StratifiedGroupKFold :\n",
    "            - strates = label (équilibrage),\n",
    "            - groupes = worm (pas de fuite),\n",
    "        - calcule F1 / Accuracy / AUC à chaque fold,\n",
    "        - stocke les moyennes.\n",
    "    - Retourne un DataFrame de résultats, trié par nombre de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_subsets(df, y, groups, feature_subsets, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Effectue une cross-validation groupée (par ver) pour chaque subset de features.\n",
    "    Retourne un DataFrame avec F1, AUC, Accuracy moyens.\n",
    "    \"\"\"\n",
    "    cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    results = []\n",
    "\n",
    "    for name, feats in feature_subsets.items():\n",
    "        print(f\"\\n--- Testing subset: {name} ({len(feats)} features) ---\")\n",
    "\n",
    "        X = df[feats].copy()\n",
    "        X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "        clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"gb\", GradientBoostingClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                random_state=random_state\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        f1s, accs, aucs = [], [], []\n",
    "\n",
    "        for train_idx, test_idx in cv.split(X, y, groups):\n",
    "            X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "            clf.fit(X_tr, y_tr)\n",
    "\n",
    "            proba = clf.predict_proba(X_te)[:, 1]\n",
    "            preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "            f1s.append(f1_score(y_te, preds))\n",
    "            accs.append(accuracy_score(y_te, preds))\n",
    "            aucs.append(roc_auc_score(y_te, proba))\n",
    "\n",
    "        results.append({\n",
    "            \"subset\": name,\n",
    "            \"n_features\": len(feats),\n",
    "            \"F1_mean\": np.mean(f1s),\n",
    "            \"ACC_mean\": np.mean(accs),\n",
    "            \"AUC_mean\": np.mean(aucs),\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"n_features\")\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lance l'evaluation et affiche les resultats: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "=== RESULTS (Minimal Feature Model) ===\n",
      "\n",
      "1_feature       |  1 feats | F1=0.530 | AUC=0.790 | ACC=0.766\n",
      "2_features      |  2 feats | F1=0.520 | AUC=0.811 | ACC=0.763\n",
      "3_features      |  3 feats | F1=0.521 | AUC=0.811 | ACC=0.764\n",
      "4_features      |  4 feats | F1=0.514 | AUC=0.811 | ACC=0.760\n",
      "6_features      |  6 feats | F1=0.502 | AUC=0.811 | ACC=0.759\n",
      "all_top_aging   | 29 feats | F1=0.529 | AUC=0.820 | ACC=0.768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>n_features</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>ACC_mean</th>\n",
       "      <th>AUC_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529918</td>\n",
       "      <td>0.765743</td>\n",
       "      <td>0.790479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.519876</td>\n",
       "      <td>0.763424</td>\n",
       "      <td>0.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.520641</td>\n",
       "      <td>0.763561</td>\n",
       "      <td>0.811288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.514110</td>\n",
       "      <td>0.760427</td>\n",
       "      <td>0.810950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.502084</td>\n",
       "      <td>0.758742</td>\n",
       "      <td>0.811207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.529138</td>\n",
       "      <td>0.768254</td>\n",
       "      <td>0.820055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subset  n_features   F1_mean  ACC_mean  AUC_mean\n",
       "0      1_feature           1  0.529918  0.765743  0.790479\n",
       "1     2_features           2  0.519876  0.763424  0.810700\n",
       "2     3_features           3  0.520641  0.763561  0.811288\n",
       "3     4_features           4  0.514110  0.760427  0.810950\n",
       "4     6_features           6  0.502084  0.758742  0.811207\n",
       "5  all_top_aging          29  0.529138  0.768254  0.820055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = evaluate_feature_subsets(df, y, groups, feature_subsets, n_splits=5, random_state=42)\n",
    "\n",
    "print(\"\\n=== RESULTS (Minimal Feature Model) ===\\n\")\n",
    "for _, r in results_df.iterrows():\n",
    "    print(\n",
    "        f\"{r['subset']:15s} | \"\n",
    "        f\"{int(r['n_features']):2d} feats | \"\n",
    "        f\"F1={r['F1_mean']:.3f} | \"\n",
    "        f\"AUC={r['AUC_mean']:.3f} | \"\n",
    "        f\"ACC={r['ACC_mean']:.3f}\"\n",
    "    )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remarque: F1 ~0.52 pour 1 à 29 features, AUC ~0.79–0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petit plot pour visualiser: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Plot: performance vs number of features ===\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(results_df[\"n_features\"], results_df[\"F1_mean\"], marker=\"o\", label=\"F1\")\n",
    "plt.plot(results_df[\"n_features\"], results_df[\"AUC_mean\"], marker=\"s\", label=\"AUC\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Minimal Feature Model: performance vs number of features\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only one feature (mean speed) already gives an F1-score around 0.53 and an AUC around 0.79.\n",
    "Extending the feature set to 2–6 features (adding speed entropy, roaming score, fraction paused, movement efficiency, high activity fraction) does not significantly change the F1-score and increases AUC only marginally.\n",
    "The full 29-feature model reaches an AUC ≈ 0.82, suggesting that a small set of 3–6 features captures most of the predictive signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance des features pour un subset choisi (un peu comme ce que l'assistant a deja fait en vrai )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature importances for subset: 6_features\n",
      "Features: ['mean_speed', 'speed_entropy', 'mean_roaming_score', 'fraction_paused', 'movement_efficiency', 'high_activity_fraction']\n",
      "\n",
      "=== Feature importances (Gradient Boosting) ===\n",
      "mean_roaming_score             0.4788\n",
      "mean_speed                     0.2062\n",
      "speed_entropy                  0.1441\n",
      "fraction_paused                0.0940\n",
      "movement_efficiency            0.0628\n",
      "high_activity_fraction         0.0140\n"
     ]
    }
   ],
   "source": [
    "# === Feature importance analysis for a chosen subset ===\n",
    "\n",
    "subset_for_importance = \"6_features\"  # ou \"all_top_aging\", comme tu veux\n",
    "feats = feature_subsets[subset_for_importance]\n",
    "\n",
    "print(f\"Computing feature importances for subset: {subset_for_importance}\")\n",
    "print(\"Features:\", feats)\n",
    "\n",
    "X_imp = df[feats].copy()\n",
    "X_imp = X_imp.fillna(X_imp.median(numeric_only=True))\n",
    "y_imp = df[\"close_to_death\"].values\n",
    "\n",
    "gb_imp = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_imp.fit(X_imp, y_imp)\n",
    "\n",
    "importances = gb_imp.feature_importances_\n",
    "sorted_feats = sorted(zip(feats, importances), key=lambda x: -x[1])\n",
    "\n",
    "print(\"\\n=== Feature importances (Gradient Boosting) ===\")\n",
    "for f, w in sorted_feats:\n",
    "    print(f\"{f:30s} {w:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remarque pourquoi la c'est mean_roaming_score le plus important wtf? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARER PLUSIEURS MODELES SUR LE MEILLEUR SUBSET \n",
    "on choisi le subset qu'on veut et on teste avec des methodes differentes:\n",
    "- GradientBoosting \n",
    "- Logistic Regression\n",
    "- Linear SVM calibré (pour obtenir des probabilités, donc un AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model comparison using subset: 3_features\n",
      "Features: ['mean_speed', 'speed_entropy', 'mean_roaming_score']\n",
      "\n",
      "--- Training GradientBoosting ---\n",
      "GradientBoosting   | ACC=0.712 | F1=0.653 | AUC=0.772\n",
      "\n",
      "--- Training LogisticRegression ---\n",
      "LogisticRegression | ACC=0.674 | F1=0.648 | AUC=0.739\n",
      "\n",
      "--- Training LinearSVM ---\n",
      "LinearSVM          | ACC=0.681 | F1=0.614 | AUC=0.738\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.711636</td>\n",
       "      <td>0.653144</td>\n",
       "      <td>0.772389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.673974</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>0.739008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0.681282</td>\n",
       "      <td>0.614023</td>\n",
       "      <td>0.738411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model       ACC        F1       AUC\n",
       "0    GradientBoosting  0.711636  0.653144  0.772389\n",
       "1  LogisticRegression  0.673974  0.648485  0.739008\n",
       "2           LinearSVM  0.681282  0.614023  0.738411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Model comparison on a chosen feature subset ===\n",
    "\n",
    "subset_for_models = \"3_features\"  # A CHANGER AVEC LES SUBSET QU'ON VEUT\n",
    "feats = feature_subsets[subset_for_models]\n",
    "\n",
    "print(f\"Model comparison using subset: {subset_for_models}\")\n",
    "print(\"Features:\", feats)\n",
    "\n",
    "X_all = df[feats].copy().fillna(df[feats].median(numeric_only=True))\n",
    "y_all = df[\"close_to_death\"].values\n",
    "groups_all = df[\"original_file\"].values\n",
    "\n",
    "# Split train/test par ver -> J'AIMERAI BIEN FAIRE UNE FONCTION POUR CE TRUC QUE J'AI JUSTE A RAPPELER DE TEMPS A AUTRE \n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "train_idx, test_idx = next(gss.split(X_all, y_all, groups=groups_all))\n",
    "\n",
    "X_train, X_test = X_all.iloc[train_idx], X_all.iloc[test_idx]\n",
    "y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=500,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LinearSVM\": CalibratedClassifierCV(\n",
    "        LinearSVC(\n",
    "            C=1.0,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        ),\n",
    "        method=\"sigmoid\",\n",
    "        cv=3\n",
    "    )\n",
    "}\n",
    "\n",
    "results_models = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    model.fit(X_train_sc, y_train)\n",
    "\n",
    "    proba = model.predict_proba(X_test_sc)[:, 1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "\n",
    "    print(f\"{name:18s} | ACC={acc:.3f} | F1={f1:.3f} | AUC={auc:.3f}\")\n",
    "\n",
    "    results_models.append({\n",
    "        \"model\": name,\n",
    "        \"ACC\": acc,\n",
    "        \"F1\": f1,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "results_models_df = pd.DataFrame(results_models)\n",
    "display(results_models_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimiser le threshold de 0.5 pour notre modele prefere: (gradient boosting sur 3_features par exemple)\n",
    "et montrer performance pour un seuil standard de 0.5 et performance pour un threshold optimise pour F1 sur un set de validation (toujours par worm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold tuning using subset: 3_features\n",
      "Features: ['mean_speed', 'speed_entropy', 'mean_roaming_score']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/d9g9nzhn7kz37clx5cr7kglc0000gn/T/ipykernel_7029/2911937795.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  f1s = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold on validation (max F1): 0.322\n",
      "Validation F1 at best threshold: 0.681\n",
      "\n",
      "=== Test performance (default threshold 0.5) ===\n",
      "ACC=0.749 | F1=0.663 | AUC=0.805\n",
      "\n",
      "=== Test performance (optimized threshold) ===\n",
      "ACC=0.745 | F1=0.705 | AUC=0.805\n"
     ]
    }
   ],
   "source": [
    "# === Threshold optimization for GradientBoosting on the same subset ===\n",
    "\n",
    "subset_for_threshold = \"3_features\"  # ou \"6_features\"\n",
    "feats = feature_subsets[subset_for_threshold]\n",
    "\n",
    "print(f\"Threshold tuning using subset: {subset_for_threshold}\")\n",
    "print(\"Features:\", feats)\n",
    "\n",
    "X_all = df[feats].copy().fillna(df[feats].median(numeric_only=True))\n",
    "y_all = df[\"close_to_death\"].values\n",
    "groups_all = df[\"original_file\"].values\n",
    "\n",
    "# 1) Split global: train+val vs test\n",
    "gss_outer = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=11)\n",
    "trainval_idx, test_idx = next(gss_outer.split(X_all, y_all, groups=groups_all))\n",
    "\n",
    "X_trainval, X_test = X_all.iloc[trainval_idx], X_all.iloc[test_idx]\n",
    "y_trainval, y_test = y_all[trainval_idx], y_all[test_idx]\n",
    "groups_trainval = groups_all[trainval_idx]\n",
    "\n",
    "# 2) Split trainval: inner-train vs val (pour choisir le threshold)\n",
    "gss_inner = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=22)\n",
    "inner_train_idx, val_idx = next(gss_inner.split(X_trainval, y_trainval, groups=groups_trainval))\n",
    "\n",
    "X_inner_train, X_val = X_trainval.iloc[inner_train_idx], X_trainval.iloc[val_idx]\n",
    "y_inner_train, y_val = y_trainval[inner_train_idx], y_trainval[val_idx]\n",
    "\n",
    "# Standardisation\n",
    "scaler_thr = StandardScaler()\n",
    "X_inner_train_sc = scaler_thr.fit_transform(X_inner_train)\n",
    "X_val_sc = scaler_thr.transform(X_val)\n",
    "X_test_sc = scaler_thr.transform(X_test)\n",
    "\n",
    "gb_thr = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Entraînement sur inner-train, choix du threshold sur val\n",
    "gb_thr.fit(X_inner_train_sc, y_inner_train)\n",
    "val_proba = gb_thr.predict_proba(X_val_sc)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, val_proba)\n",
    "f1s = 2 * (precision * recall) / (precision + recall)\n",
    "f1s = f1s[:-1]  # la dernière valeur n'a pas de threshold associé\n",
    "thresholds = thresholds\n",
    "\n",
    "best_idx = np.nanargmax(f1s)\n",
    "best_thr = thresholds[best_idx]\n",
    "\n",
    "print(f\"Best threshold on validation (max F1): {best_thr:.3f}\")\n",
    "print(f\"Validation F1 at best threshold: {f1s[best_idx]:.3f}\")\n",
    "\n",
    "# 4) Ré-entraîner sur tout trainval et évaluer sur test\n",
    "gb_thr.fit(scaler_thr.transform(X_trainval), y_trainval)\n",
    "test_proba = gb_thr.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "preds_default = (test_proba >= 0.5).astype(int)\n",
    "preds_best = (test_proba >= best_thr).astype(int)\n",
    "\n",
    "acc_default = accuracy_score(y_test, preds_default)\n",
    "f1_default = f1_score(y_test, preds_default)\n",
    "auc_default = roc_auc_score(y_test, test_proba)\n",
    "\n",
    "acc_best = accuracy_score(y_test, preds_best)\n",
    "f1_best = f1_score(y_test, preds_best)\n",
    "auc_best = auc_default  # AUC ne dépend pas du threshold\n",
    "\n",
    "print(\"\\n=== Test performance (default threshold 0.5) ===\")\n",
    "print(f\"ACC={acc_default:.3f} | F1={f1_default:.3f} | AUC={auc_default:.3f}\")\n",
    "\n",
    "print(\"\\n=== Test performance (optimized threshold) ===\")\n",
    "print(f\"ACC={acc_best:.3f} | F1={f1_best:.3f} | AUC={auc_best:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEster notre threshold de close to death( qui etait a 20 segment: go le tester et voir si on a des meilleurs resultats)\n",
    "\n",
    "- teste plusieurs thresholds : 5, 10, 15, 20, 25, 30\n",
    "- recalcule le label near-death\n",
    "- réutilise la cross-validation par worm\n",
    "\n",
    "(met un peu de temps a run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Testing threshold = 5 segments\n",
      "==============================\n",
      "Label distribution: [7582  615]\n",
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "==============================\n",
      " Testing threshold = 10 segments\n",
      "==============================\n",
      "Label distribution: [7071 1126]\n",
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "==============================\n",
      " Testing threshold = 15 segments\n",
      "==============================\n",
      "Label distribution: [6570 1627]\n",
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "==============================\n",
      " Testing threshold = 20 segments\n",
      "==============================\n",
      "Label distribution: [6061 2136]\n",
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "==============================\n",
      " Testing threshold = 25 segments\n",
      "==============================\n",
      "Label distribution: [5554 2643]\n",
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "==============================\n",
      " Testing threshold = 30 segments\n",
      "==============================\n",
      "Label distribution: [5038 3159]\n",
      "\n",
      "--- Testing subset: 1_feature (1 features) ---\n",
      "\n",
      "--- Testing subset: 2_features (2 features) ---\n",
      "\n",
      "--- Testing subset: 3_features (3 features) ---\n",
      "\n",
      "--- Testing subset: 4_features (4 features) ---\n",
      "\n",
      "--- Testing subset: 6_features (6 features) ---\n",
      "\n",
      "--- Testing subset: all_top_aging (29 features) ---\n",
      "\n",
      "=== SUMMARY: Performance vs threshold ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>n_features</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>ACC_mean</th>\n",
       "      <th>AUC_mean</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.915714</td>\n",
       "      <td>0.799386</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070355</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>0.814345</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055436</td>\n",
       "      <td>0.916632</td>\n",
       "      <td>0.816439</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>0.919183</td>\n",
       "      <td>0.820498</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.102604</td>\n",
       "      <td>0.921190</td>\n",
       "      <td>0.817366</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.124034</td>\n",
       "      <td>0.922290</td>\n",
       "      <td>0.818346</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137170</td>\n",
       "      <td>0.850827</td>\n",
       "      <td>0.795380</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.174341</td>\n",
       "      <td>0.849825</td>\n",
       "      <td>0.819910</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.179593</td>\n",
       "      <td>0.852123</td>\n",
       "      <td>0.821921</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.820535</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.221804</td>\n",
       "      <td>0.853612</td>\n",
       "      <td>0.824358</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.245320</td>\n",
       "      <td>0.853222</td>\n",
       "      <td>0.831347</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309010</td>\n",
       "      <td>0.790018</td>\n",
       "      <td>0.797337</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.378025</td>\n",
       "      <td>0.796636</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.372999</td>\n",
       "      <td>0.794260</td>\n",
       "      <td>0.814343</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.353070</td>\n",
       "      <td>0.789524</td>\n",
       "      <td>0.808484</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.370480</td>\n",
       "      <td>0.795721</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.393317</td>\n",
       "      <td>0.797188</td>\n",
       "      <td>0.818641</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529918</td>\n",
       "      <td>0.765743</td>\n",
       "      <td>0.790479</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.519876</td>\n",
       "      <td>0.763424</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.520641</td>\n",
       "      <td>0.763561</td>\n",
       "      <td>0.811288</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.514110</td>\n",
       "      <td>0.760427</td>\n",
       "      <td>0.810950</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.502084</td>\n",
       "      <td>0.758742</td>\n",
       "      <td>0.811207</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.529138</td>\n",
       "      <td>0.768254</td>\n",
       "      <td>0.820055</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618928</td>\n",
       "      <td>0.754747</td>\n",
       "      <td>0.793787</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.619417</td>\n",
       "      <td>0.755448</td>\n",
       "      <td>0.810845</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.757548</td>\n",
       "      <td>0.808808</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.616985</td>\n",
       "      <td>0.753026</td>\n",
       "      <td>0.811283</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617079</td>\n",
       "      <td>0.755988</td>\n",
       "      <td>0.811493</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.630968</td>\n",
       "      <td>0.761430</td>\n",
       "      <td>0.820553</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1_feature</td>\n",
       "      <td>1</td>\n",
       "      <td>0.669766</td>\n",
       "      <td>0.747950</td>\n",
       "      <td>0.792515</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2_features</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675373</td>\n",
       "      <td>0.749124</td>\n",
       "      <td>0.803503</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3_features</td>\n",
       "      <td>3</td>\n",
       "      <td>0.672137</td>\n",
       "      <td>0.747371</td>\n",
       "      <td>0.805072</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4_features</td>\n",
       "      <td>4</td>\n",
       "      <td>0.676448</td>\n",
       "      <td>0.750542</td>\n",
       "      <td>0.805984</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6_features</td>\n",
       "      <td>6</td>\n",
       "      <td>0.673087</td>\n",
       "      <td>0.749005</td>\n",
       "      <td>0.807450</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>all_top_aging</td>\n",
       "      <td>29</td>\n",
       "      <td>0.682405</td>\n",
       "      <td>0.752569</td>\n",
       "      <td>0.817465</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subset  n_features   F1_mean  ACC_mean  AUC_mean  threshold\n",
       "0       1_feature           1  0.061080  0.915714  0.799386          5\n",
       "1      2_features           2  0.070355  0.916255  0.814345          5\n",
       "2      3_features           3  0.055436  0.916632  0.816439          5\n",
       "3      4_features           4  0.051069  0.919183  0.820498          5\n",
       "4      6_features           6  0.102604  0.921190  0.817366          5\n",
       "5   all_top_aging          29  0.124034  0.922290  0.818346          5\n",
       "6       1_feature           1  0.137170  0.850827  0.795380         10\n",
       "7      2_features           2  0.174341  0.849825  0.819910         10\n",
       "8      3_features           3  0.179593  0.852123  0.821921         10\n",
       "9      4_features           4  0.188891  0.849032  0.820535         10\n",
       "10     6_features           6  0.221804  0.853612  0.824358         10\n",
       "11  all_top_aging          29  0.245320  0.853222  0.831347         10\n",
       "12      1_feature           1  0.309010  0.790018  0.797337         15\n",
       "13     2_features           2  0.378025  0.796636  0.816536         15\n",
       "14     3_features           3  0.372999  0.794260  0.814343         15\n",
       "15     4_features           4  0.353070  0.789524  0.808484         15\n",
       "16     6_features           6  0.370480  0.795721  0.811327         15\n",
       "17  all_top_aging          29  0.393317  0.797188  0.818641         15\n",
       "18      1_feature           1  0.529918  0.765743  0.790479         20\n",
       "19     2_features           2  0.519876  0.763424  0.810700         20\n",
       "20     3_features           3  0.520641  0.763561  0.811288         20\n",
       "21     4_features           4  0.514110  0.760427  0.810950         20\n",
       "22     6_features           6  0.502084  0.758742  0.811207         20\n",
       "23  all_top_aging          29  0.529138  0.768254  0.820055         20\n",
       "24      1_feature           1  0.618928  0.754747  0.793787         25\n",
       "25     2_features           2  0.619417  0.755448  0.810845         25\n",
       "26     3_features           3  0.625800  0.757548  0.808808         25\n",
       "27     4_features           4  0.616985  0.753026  0.811283         25\n",
       "28     6_features           6  0.617079  0.755988  0.811493         25\n",
       "29  all_top_aging          29  0.630968  0.761430  0.820553         25\n",
       "30      1_feature           1  0.669766  0.747950  0.792515         30\n",
       "31     2_features           2  0.675373  0.749124  0.803503         30\n",
       "32     3_features           3  0.672137  0.747371  0.805072         30\n",
       "33     4_features           4  0.676448  0.750542  0.805984         30\n",
       "34     6_features           6  0.673087  0.749005  0.807450         30\n",
       "35  all_top_aging          29  0.682405  0.752569  0.817465         30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Sensitivity analysis: effect of threshold on near-death definition ===\n",
    "\n",
    "thresholds = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "all_threshold_results = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Testing threshold = {thr} segments\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # Recompute label with new threshold\n",
    "    df[\"close_to_death\"] = (df[\"segments_from_end\"] <= thr).astype(int)\n",
    "    y = df[\"close_to_death\"].values\n",
    "\n",
    "    # Check class balance\n",
    "    print(\"Label distribution:\", np.bincount(df[\"close_to_death\"]))\n",
    "\n",
    "    # Evaluate on all feature subsets\n",
    "    res_thr = evaluate_feature_subsets(df, y, groups, feature_subsets, n_splits=5)\n",
    "    res_thr[\"threshold\"] = thr\n",
    "    \n",
    "    all_threshold_results.append(res_thr)\n",
    "\n",
    "# Concatenate results\n",
    "results_thresholds = pd.concat(all_threshold_results, ignore_index=True)\n",
    "\n",
    "print(\"\\n=== SUMMARY: Performance vs threshold ===\\n\")\n",
    "display(results_thresholds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celegans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
